# docker-compose.yml (FINAL, ENHANCED VERSION)

version: "3.8"

services:

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: meeting_api_server
    command: "uvicorn app.main:app --host 0.0.0.0 --port 8072 --reload"
    ports:
      - "8072:8072"
    volumes:
      - ./app:/code/app
      - ./shared_audio:/code/shared_audio
    env_file: .env
    restart: unless-stopped

  worker-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: meeting_gpu_worker
    command: >
      celery -A app.worker.celery_app worker -l info 
      --pool=solo 
      -Q gpu_tasks 
      --concurrency=1
    
    # --- THE DEFINITIVE FIX IS HERE ---
    environment:
      # Explicitly tell the container where to find the NVIDIA libraries.
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu
      
    volumes:
      - ./app:/code/app
      - ./shared_audio:/code/shared_audio
      # Mount BOTH the standard system library path AND the specific CUDA toolkit path.
      # This provides maximum compatibility.
      - /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu
      - /usr/local/cuda-12.2/targets/x86_64-linux/lib:/usr/local/cuda/lib64
    # --- END OF FIX ---
      
    env_file: .env
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  worker-cpu:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: meeting_cpu_worker
    command: >
      celery -A app.worker.celery_app worker -l info 
      -Q cpu_tasks 
      --concurrency=4
    volumes:
      - ./app:/code/app
      - ./shared_audio:/code/shared_audio
    env_file: .env
    restart: unless-stopped
