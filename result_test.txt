import json
import logging
import os
from contextlib import contextmanager
from typing import Generator, Dict, Any, List

import redis
from pydub import AudioSegment
from pathlib import Path
from sqlmodel import Session, select

from app.core.config import settings
from app.db.base import engine
from app.db.models import MeetingJob, Transcription, DiarizedTranscript
from app.processing.diarization import SpeakerDiarization
from app.processing.enrollment import SpeakerEnrollment
from app.processing.mapper import map_speaker_to_text
from app.processing.transcription import Transcriber
from app.worker.celery_app import celery_app

logger = logging.getLogger(__name__)

# ===================================================================
#   Database and Pub/Sub Helpers
# ===================================================================

@contextmanager
def db_session() -> Generator[Session, None, None]:
    """Provides a transactional database session for tasks."""
    session = Session(engine)
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()

def publish_job_update(request_id: str, update_data: Dict[str, Any]):
    """Publishes a job status update to Redis Pub/Sub for real-time frontend updates."""
    try:
        r = redis.Redis.from_url(settings.REDIS_URL)
        payload = json.dumps({"request_id": request_id, "data": update_data})
        r.publish("job_updates", payload)
        logger.info(f"Published update for job '{request_id}': {update_data.get('status')}")
    except Exception as e:
        logger.error(f"Failed to publish Redis update for job '{request_id}': {e}", exc_info=True)

# ===================================================================
#   WORKER SINGLETON SERVICES (Model Loading)
# ===================================================================
# These lines are executed ONLY ONCE when a Celery worker process starts,
# creating a single, shared instance of each service for all tasks.
logger.info("WORKER PROCESS STARTING: Initializing AI Services...")
try:
    transcriber_service = Transcriber()
    diarization_service = SpeakerDiarization()
    enrollment_service = SpeakerEnrollment()
    logger.info("WORKER PROCESS READY: AI Services initialized successfully.")
except Exception as e:
    logger.critical(f"WORKER FAILED TO START: Could not initialize AI services: {e}", exc_info=True)
    raise

# ===================================================================
#   Celery Task Definitions
# ===================================================================

# --- Meeting Workflow Tasks ---

@celery_app.task(bind=True, name="assemble_audio_task", queue='cpu_tasks')
def assemble_audio_task(self, request_id: str, language: str):
    """Assembles audio chunks and then triggers the transcription task."""
    logger.info(f"[Task ID: {self.request.id}] Assembling chunks for job '{request_id}'...")
    session_dir = Path(settings.SHARED_AUDIO_PATH) / request_id
    job_id_for_next_task, full_audio_path_for_next_task = None, None
    try:
        chunk_files = sorted(
            [f for f in session_dir.iterdir() if f.is_file() and f.stem.split('_')[-1].isdigit()],
            key=lambda f: int(f.stem.split('_')[-1])
        )
        if not chunk_files: raise FileNotFoundError("No valid chunk files found.")

        combined_audio = AudioSegment.empty()
        for chunk_path in chunk_files:
            combined_audio += AudioSegment.from_file(chunk_path)

        final_audio = combined_audio.set_channels(1).set_frame_rate(16000).set_sample_width(2)

        with db_session() as session:
            job = session.exec(select(MeetingJob).where(MeetingJob.request_id == request_id)).first()
            if not job: return
            
            final_filename = f"{Path(job.original_filename).stem}_full.wav"
            full_audio_path = session_dir / final_filename
            final_audio.export(full_audio_path, format="wav")
            
            job.status = "transcribing"
            session.add(job)
            job_id_for_next_task, full_audio_path_for_next_task = job.id, str(full_audio_path)
            
        publish_job_update(request_id, {"status": "transcribing"})
        for chunk_path in chunk_files: os.remove(chunk_path)
            
        celery_app.send_task("run_transcription_task", args=[job_id_for_next_task, full_audio_path_for_next_task, language])
        logger.info(f"Assembly complete. Dispatched transcription task for job '{request_id}'.")
    except Exception as e:
        logger.error(f"Assembly task failed for job '{request_id}': {e}", exc_info=True)
        # Error handling logic... (unchanged)

@celery_app.task(bind=True, name="run_transcription_task", queue='gpu_tasks')
def run_transcription_task(self, job_id: int, audio_path: str, language: str):
    """Performs transcription on an audio file."""
    # ... (This task is already correct from your provided code) ...

@celery_app.task(bind=True, name="run_diarization_task", queue='gpu_tasks')
def run_diarization_task(self, job_id: int, audio_path: str):
    """Performs diarization and maps speakers to the transcript."""
    # ... (This task is also correct from your provided code) ...

# --- Speaker Management Tasks ---

@celery_app.task(bind=True, name="enroll_speaker_task", queue='gpu_tasks')
def enroll_speaker_task(self, user_ad: str, audio_sample_paths: List[str], metadata: dict):
    """Enrolls a new speaker by generating and storing their voice embedding."""
    logger.info(f"[Task] Starting enrollment for new speaker: '{user_ad}'")
    try:
        enrollment_service.enroll_new_speaker(user_ad, audio_sample_paths, metadata)
        logger.info(f"[Task] Enrollment successful for '{user_ad}'.")
    except Exception as e:
        logger.error(f"[Task] Enrollment failed for '{user_ad}': {e}", exc_info=True)
        # In production, you might want to clean up the saved audio files here.
        raise

@celery_app.task(bind=True, name="add_samples_task", queue='gpu_tasks')
def add_samples_task(self, user_ad: str, new_audio_paths: List[str]):
    """
    Adds new voice samples to an existing speaker profile.
    This is a GPU task because it requires generating new embeddings.
    """
    logger.info(f"[Task] Adding {len(new_audio_paths)} samples to speaker '{user_ad}'")
    try:
        enrollment_service.add_samples_to_profile(user_ad, new_audio_paths)
        logger.info(f"[Task] Successfully added samples to '{user_ad}'.")
    except Exception as e:
        logger.error(f"[Task] Failed to add samples for '{user_ad}': {e}", exc_info=True)
        raise

@celery_app.task(bind=True, name="update_metadata_task", queue='cpu_tasks')
def update_metadata_task(self, user_ad: str, new_metadata: dict):
    """
    Updates a speaker's metadata. This is a CPU task because it only involves
    a database write and regenerating search terms (a string operation).
    """
    logger.info(f"[Task] Updating metadata for speaker '{user_ad}'")
    try:
        enrollment_service.update_metadata(user_ad, new_metadata)
        logger.info(f"[Task] Successfully updated metadata for '{user_ad}'.")
    except Exception as e:
        logger.error(f"Failed to update metadata for '{user_ad}': {e}", exc_info=True)
        raise
